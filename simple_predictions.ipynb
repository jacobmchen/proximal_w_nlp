{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  patient_id  afib  \\\n",
      "0          0         109     0   \n",
      "1          2         113     0   \n",
      "2          3         114     0   \n",
      "3          4         115     0   \n",
      "4          6         117     0   \n",
      "...      ...         ...   ...   \n",
      "29446  46515       97164     0   \n",
      "29447  46516       97484     0   \n",
      "29448  46517       97488     1   \n",
      "29449  46518       97492     0   \n",
      "29450  46519       97497     1   \n",
      "\n",
      "                                                   notes  age  \\\n",
      "0      PATIENT/TEST INFORMATION: Indication: Code. As...   25   \n",
      "1      Sinus rhythm, rate 93. Non-specific ST-T wave ...   35   \n",
      "2      Normal sinus rhythm, rate 96 Right bundle bran...   48   \n",
      "3      PATIENT/TEST INFORMATION: Indication: Left ven...   75   \n",
      "4      PATIENT/TEST INFORMATION: Indication: Murmur. ...   50   \n",
      "...                                                  ...  ...   \n",
      "29446  PATIENT/TEST INFORMATION: Indication: Aortic v...   83   \n",
      "29447  Sinus bradycardia with non-diagnostic repolari...   79   \n",
      "29448  PATIENT/TEST INFORMATION: Indication: Stroke  ...   67   \n",
      "29449  PATIENT/TEST INFORMATION: Indication: Cerebrov...   32   \n",
      "29450  PATIENT/TEST INFORMATION: Indication: Left ven...   58   \n",
      "\n",
      "                                             notes_half1  \\\n",
      "0      PATIENT/TEST INFORMATION: Indication: Code. As...   \n",
      "1      Sinus rhythm, rate 93. Non-specific ST-T wave ...   \n",
      "2      Normal sinus rhythm, rate 96 Right bundle bran...   \n",
      "3      PATIENT/TEST INFORMATION: Indication: Left ven...   \n",
      "4      PATIENT/TEST INFORMATION: Indication: Murmur. ...   \n",
      "...                                                  ...   \n",
      "29446  PATIENT/TEST INFORMATION: Indication: Aortic v...   \n",
      "29447  Sinus bradycardia with non-diagnostic repolari...   \n",
      "29448  PATIENT/TEST INFORMATION: Indication: Stroke  ...   \n",
      "29449  PATIENT/TEST INFORMATION: Indication: Cerebrov...   \n",
      "29450  PATIENT/TEST INFORMATION: Indication: Left ven...   \n",
      "\n",
      "                                             notes_half2  \n",
      "0      RICLE: RV hypertrophy.  PERICARDIUM: Small per...  \n",
      "1      ities. No previous tracing available for compa...  \n",
      "2      ge indeterminate Probable anterolateral subepi...  \n",
      "3       MR.  PERICARDIUM: No pericardial effusion.  G...  \n",
      "4      ned tricuspid valve leaflets. Moderate [2+] TR...  \n",
      "...                                                  ...  \n",
      "29446  Last Name (Titles) 2**] throughout the procedu...  \n",
      "29447  malities.  No previous tracing available for c...  \n",
      "29448  n. There is an anterior space which most likel...  \n",
      "29449  aflets with trivial MR.  TRICUSPID VALVE: Norm...  \n",
      "29450  CUSPID VALVE: Normal tricuspid valve leaflets ...  \n",
      "\n",
      "[29451 rows x 7 columns]\n",
      "0.2785304403925164\n"
     ]
    }
   ],
   "source": [
    "# load the afib diagnosis and patient notes data\n",
    "afib_data = pd.read_csv('processed_afib_data.csv')\n",
    "print(afib_data)\n",
    "print(np.mean(afib_data['afib']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Linear Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting atrial fibrillation using only first half of the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jchen/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=1e+20))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=1e+20))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1e+20)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('lr', LogisticRegression(C=1e+20))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a simple bag of words linear logistic regression to predict if a patient suffered from afib\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(C=1e20)),\n",
    "])\n",
    "\n",
    "text_clf.fit(afib_data['notes'], afib_data['afib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7676479576245289\n"
     ]
    }
   ],
   "source": [
    "# make predictions from the original dataset\n",
    "predicted = text_clf.predict(afib_data['notes_half1'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20123 1125 5718 2485\n",
      "sensitivity:  0.3029379495306595\n",
      "specificity:  0.9470538403614458\n",
      "precision:  0.6883656509695291\n",
      "recall:  0.3029379495306595\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting atrial fibrillation using only the second half of the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a simple bag of words linear logistic regression to predict if a patient suffered from afib\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(C=1e20)),\n",
    "])\n",
    "\n",
    "text_clf.fit(afib_data['notes'], afib_data['afib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749889647210621\n"
     ]
    }
   ],
   "source": [
    "# make predictions from the original dataset\n",
    "predicted = text_clf.predict(afib_data['notes_half2'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19743 1505 5861 2342\n",
      "sensitivity:  0.2855053029379495\n",
      "specificity:  0.9291698042168675\n",
      "precision:  0.6087860670652456\n",
      "recall:  0.2855053029379495\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now train a BoW model that only uses the first 5,000 most important words in the vocabulary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting atrial fibrillation using only the first half of the note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "word_count = count_vect.fit_transform(afib_data['notes'])\n",
    "\n",
    "vocab = str(count_vect.vocabulary_)\n",
    "vocab = vocab.replace(',', '\\n')\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jchen/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=1e+20))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(C=1e+20))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=5000, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1e+20)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('lr', LogisticRegression(C=1e+20))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a simple bag of words linear logistic regression to predict if a patient suffered from afib, but only considering the 5000 most\n",
    "# frequently occurring words and also considering both unigrams and bigrams\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(C=1e20)),\n",
    "])\n",
    "\n",
    "text_clf.fit(afib_data['notes'], afib_data['afib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8383756069403416\n"
     ]
    }
   ],
   "source": [
    "# make predictions from the original dataset\n",
    "predicted = text_clf.predict(afib_data['notes'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19722 1526 3234 4969\n",
      "sensitivity:  0.6057539924417896\n",
      "specificity:  0.9281814759036144\n",
      "precision:  0.765050038491147\n",
      "recall:  0.6057539924417896\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804454857220468\n"
     ]
    }
   ],
   "source": [
    "# make predictions from the original dataset\n",
    "predicted = text_clf.predict(afib_data['notes_half1'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19794 1454 4305 3898\n",
      "sensitivity:  0.47519200292575886\n",
      "specificity:  0.9315700301204819\n",
      "precision:  0.7283258594917787\n",
      "recall:  0.47519200292575886\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting atrial fibrillation using only the second half of the note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762384978438762\n"
     ]
    }
   ],
   "source": [
    "# make predictions from the original dataset\n",
    "predicted = text_clf.predict(afib_data['notes_half2'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20192 1056 5534 2669\n",
      "sensitivity:  0.32536876752407656\n",
      "specificity:  0.9503012048192772\n",
      "precision:  0.7165100671140939\n",
      "recall:  0.32536876752407656\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_expression_predict(notes):\n",
    "    prediction = []\n",
    "\n",
    "    for note in notes:\n",
    "        note = note.lower()\n",
    "\n",
    "        # check if the phrases 'atrial fib' or 'afib' show up, if neither phrase shows up then\n",
    "        # we make a prediction that the patient did not experience atrial fibrillation, otherwise\n",
    "        # we predict that the patient did experience atrial fibrillation\n",
    "        if re.search('atrial fib', note, flags=0) == None and re.search('a-*fib', note, flags=0) == None:\n",
    "            prediction.append(0)\n",
    "        else:\n",
    "            prediction.append(1)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions based on the entire note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7927065294896608\n"
     ]
    }
   ],
   "source": [
    "# make predictions using the regular expression method\n",
    "predicted = regular_expression_predict(afib_data['notes'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20968 280 5825 2378\n",
      "sensitivity:  0.28989394124100937\n",
      "specificity:  0.9868222891566265\n",
      "precision:  0.8946576373212942\n",
      "recall:  0.28989394124100937\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions based on only the first half of the note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7805167906013378\n"
     ]
    }
   ],
   "source": [
    "# make predictions using the regular expression method\n",
    "predicted = regular_expression_predict(afib_data['notes_half1'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21021 227 6237 1966\n",
      "sensitivity:  0.23966841399487993\n",
      "specificity:  0.9893166415662651\n",
      "precision:  0.8964888280893752\n",
      "recall:  0.23966841399487993\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions based on only the second half of the note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7449662150690978\n"
     ]
    }
   ],
   "source": [
    "# make predictions using the regular expression method\n",
    "predicted = regular_expression_predict(afib_data['notes_half2'])\n",
    "\n",
    "# measure the accuracy of the predictions\n",
    "print(np.mean(afib_data['afib'] == predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21146 102 7409 794\n",
      "sensitivity:  0.09679385590637572\n",
      "specificity:  0.9951995481927711\n",
      "precision:  0.8861607142857143\n",
      "recall:  0.09679385590637572\n"
     ]
    }
   ],
   "source": [
    "# calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(afib_data['afib'], predicted).ravel()\n",
    "# print the confusion matrix\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "# calculate the sensitivity and specificty of the data\n",
    "sensitivity = tp / (tp+fn)\n",
    "specificity = tn / (fp+tn)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
